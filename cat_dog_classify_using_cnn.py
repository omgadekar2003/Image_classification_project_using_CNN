# -*- coding: utf-8 -*-
"""cat_dog_classify_using_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15CMtvpH9g1wXTiDnryA3c4_PIYvMU4Pa
"""

!wget --no-check-certificate \
    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
    -O /tmp/cats_and_dogs_filtered.zip

import os
import zipfile

local_zip = '/tmp/cats_and_dogs_filtered.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

import tensorflow

from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from keras .models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""**CNN Network:**"""

cnn = Sequential()

#filters size, kernel size, size should be 64*64 pixels & in 3 color channel
# activation function reLU:
# then adding MaxPooling2D with pool_size(2,2)
# Repeating this again to reduce image size pixels

cnn.add(Conv2D((32),(3,3),input_shape=(64,64,3),activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Conv2D((16),(3,3),activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Flatten())

"""**ANN Network**"""

# using relu in activation function and at last we wnat binary output as 0 or 1:
# so at last we're using sigmoid activation function:
cnn.add(Dense(units=64,activation='relu'))
cnn.add(Dense(units=32,activation='relu'))
cnn.add(Dense(units=16,activation='relu'))
cnn.add(Dense(units=8,activation='relu'))
cnn.add(Dense(units=4,activation='relu'))
cnn.add(Dense(units=2,activation='relu'))
cnn.add(Dense(units=1,activation='sigmoid'))

# compile modle:
cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

# training testing code from official keras Documentation
# documentation link: https://faroit.com/keras-docs/1.2.0/preprocessing/image/

train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        r'/tmp/cats_and_dogs_filtered',
        target_size=(64, 64),
        batch_size=32,
        class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
        r'/tmp/cats_and_dogs_filtered',
        target_size=(64, 64),
        batch_size=32,
        class_mode='binary')

cnn.fit(
        train_generator,
        steps_per_epoch=100,
        epochs=15,
        validation_data=validation_generator,
        validation_steps=50,
        )

"""**as we getting loss is very big but reason is simple to train this much big data model can take so much time**"""

# testing start:
#image load
from keras.preprocessing import image
import numpy as np

# upload here new image to check the prediction of separation of cat & dog
# r for relative path

img = image.load_img(r"/content/drive/MyDrive/prediction data/2008.jpg", target_size=(64,64))

# convert it into array:
img = image.img_to_array(img)

# How image look into an array:
img

# again we've to flatten it for Dimension Reduction
# we use numpy here:

img = np.expand_dims(img, axis=0)

# now add this image into prediction model
p = cnn.predict(img)
p

"""**as output is between 0 and 1 so we have to add the condition between less than 0.5 or more than 0.5**"""

if p[0][0] < 0.5:
  print("Dog")
else:
  print("Cat")

"""# We get Correct output as image of DOG"""